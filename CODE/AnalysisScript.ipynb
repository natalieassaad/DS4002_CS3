{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file splits the dataset into training and test sets using an 80-20 split. It then produces our three algorithms \n",
    "(KNN, Logistic Regression, and Decision Tree) and performs cross-validation. You will have to fill in the code for producing \n",
    "the KNN models and Decision Tree models. The models are then compared based on precision and accuracy levels, with the highest\n",
    "performing model identified at the end.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suhZ4FA8eZf0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets, neighbors\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "JDN80gStei1_",
    "outputId": "6bd8c218-9497-4a71-cfb4-49979cf506f4"
   },
   "outputs": [],
   "source": [
    "# Read in CSV of cleaned/preprocessed data\n",
    "# Change file path if necessary\n",
    "df = pd.read_csv(\"preprocessed_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZdmP6H4e-Nu"
   },
   "outputs": [],
   "source": [
    "# Extract labels and features\n",
    "X = df[\"Preprocessed Text\"]  # Preprocessed text data\n",
    "y = df[\"Spam or Not Spam\"]  # Target labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szPvam-TfwBF"
   },
   "outputs": [],
   "source": [
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LOUFmNSgdfg"
   },
   "outputs": [],
   "source": [
    "# Convert text to numerical representation using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Can fine-tune max_features\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tja16FesLTnx"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter ranges\n",
    "knn_k_values = [3, 5, 10, 15]  # Different k values for KNN\n",
    "decision_tree_depths = [5, 10, 15, 20]  # Different depths for Decision Tree\n",
    "cross_validation_levels = [5, 10, 15]  # Different levels of cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS3McAJrLY3f"
   },
   "outputs": [],
   "source": [
    "# Initialize models with tuning capability\n",
    "models = {\"Logistic Regression\": LogisticRegression(max_iter=1000)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the spaces below, write the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a for loop with the 'knn_k_values' variable to add the KNN models to the 'models' variable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, use a for loop with the 'decision_tree_depths' variable to add the decision tree \n",
    "# models to the 'models' variable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50rIh--LLt1I"
   },
   "outputs": [],
   "source": [
    "# Train, evaluate, and perform cross-validation\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    for cv in cross_validation_levels:\n",
    "        cv_scores = cross_val_score(model, X_train_tfidf, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "        # Evaluate on test set\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=\"Spam\")\n",
    "\n",
    "        # Save results to the list\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Cross-Validation Folds\": cv,\n",
    "            \"Test Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Cross-Validation Accuracy\": np.mean(cv_scores)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZLwMyX7Lx65",
    "outputId": "84065663-0638-4971-ab37-b653f55b6d12"
   },
   "outputs": [],
   "source": [
    "# Convert results to DataFrame and save as CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"model_results.csv\", index=False)\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    print(f\"{result['Model']} (CV={result['Cross-Validation Folds']}):\")\n",
    "    print(f\"  Test Accuracy: {result['Test Accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {result['Precision']:.4f}\")\n",
    "    print(f\"  Cross-Validation Accuracy: {result['Cross-Validation Accuracy']:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Identify the best performing model for accuracy\n",
    "best_model = max(results, key=lambda r: r[\"Test Accuracy\"])\n",
    "if best_model[\"Test Accuracy\"] >= 0.95:\n",
    "    print(f\"{best_model['Model']} (CV={best_model['Cross-Validation Folds']}) meets/exceeds 95% accuracy.\")\n",
    "else:\n",
    "    print(f\"No model reached 95% accuracy. Further tuning is needed.\")\n",
    "\n",
    "# Identify the best performing model for precision\n",
    "best_model = max(results, key=lambda r: r[\"Precision\"])\n",
    "if best_model[\"Precision\"] >= 0.95:\n",
    "    print(f\"{best_model['Model']} (CV={best_model['Cross-Validation Folds']}) meets/exceeds 95% precision.\")\n",
    "else:\n",
    "    print(f\"No model reached 95% precision. Further tuning is needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results CSV\n",
    "results_df = pd.read_csv(\"model_results.csv\")\n",
    "\n",
    "# Set style of graphs\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Grouped Bar Chart (for comparing all three variables between each of the models)\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics = [\"Test Accuracy\", \"Precision\", \"Cross-Validation Accuracy\"]\n",
    "results_df_melted = results_df.melt(id_vars=[\"Model\"], value_vars=metrics, var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "sns.barplot(data=results_df_melted, x=\"Model\", y=\"Score\", hue=\"Metric\", palette=\"coolwarm\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Model Comparison: Accuracy, Precision, and Cross-Validation\")\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.show()\n",
    "\n",
    "# Line Plot (for performance trends across models)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for metric in metrics:\n",
    "    sns.lineplot(data=results_df, x=\"Model\", y=metric, marker=\"o\", label=metric)\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Performance Trends Across Models\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.show()\n",
    "\n",
    "# Box Plot (showing the distribution of scores)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=results_df_melted, x=\"Metric\", y=\"Score\", hue=\"Metric\", palette=\"coolwarm\", dodge=False)\n",
    "plt.title(\"Performance Variation Across Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Load results\n",
    "results_df = pd.read_csv(\"model_results.csv\")\n",
    "\n",
    "# Encode model names numerically\n",
    "results_df[\"Model_Num\"] = results_df[\"Model\"].astype(\"category\").cat.codes  #Assigns numerical values to models\n",
    "\n",
    "# Compute Pearson Correlation\n",
    "correlations = {}\n",
    "for metric in [\"Test Accuracy\", \"Precision\", \"Cross-Validation Accuracy\"]:\n",
    "    r_value, p_value = pearsonr(results_df[\"Model_Num\"], results_df[metric])\n",
    "    correlations[metric] = {\"r-value\": r_value, \"p-value\": p_value}\n",
    "\n",
    "# Convert to DataFrame\n",
    "corr_df = pd.DataFrame.from_dict(correlations, orient=\"index\")\n",
    "print(\"Pearson Correlation Coefficients:\")\n",
    "print(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONQtP+f5M7YVMx+HsrtQLN",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
